"""
Zabbix RCA Tool - ç›£è¦–è¨­å®šç”Ÿæˆ & APIé€£æº (AI Assisted - Gemma 3)
ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰Zabbixè¨­å®šã‚’è‡ªå‹•ç”Ÿæˆã—ã€APIçµŒç”±ã§é©ç”¨ã™ã‚‹
"""

import streamlit as st
import json
import os
import requests
import pandas as pd
import time
from typing import Dict, List, Any

# Google Generative AI ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©¦è¡Œ
try:
    import google.generativeai as genai
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False

# ==================== ãƒšãƒ¼ã‚¸è¨­å®š ====================
st.set_page_config(
    page_title="ç›£è¦–è¨­å®šç”Ÿæˆ - Zabbix RCA Tool",
    page_icon="âš™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª ====================
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data")

# ==================== ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®šç¾© ====================
DEFAULT_TRIGGER_RULES = [
    {
        "id": "ping_check",
        "name": "ICMP Ping Status",
        "severity": "High",
        "description": "æ­»æ´»ç›£è¦– (0=Down, 1=Up)",
        "condition_type": "always",
        "threshold_macro": "{$ICMP_RESPONSE_TIME_WARN}",
        "default_value": "0",
        "unit": "status",
        "interval_macro": "{$ICMP_PING_INTERVAL}",
        "default_interval": "60"
    },
    {
        "id": "cpu_check",
        "name": "High CPU Utilization",
        "severity": "Warning",
        "description": "CPUä½¿ç”¨ç‡ãŒé«˜é¨°ã—ã¦ã„ã¾ã™",
        "condition_type": "always",
        "threshold_macro": "{$CPU.UTIL.CRIT}",
        "default_value": "90",
        "unit": "%",
        "interval_macro": "{$CPU_CHECK_INTERVAL}",
        "default_interval": "300"
    },
    {
        "id": "psu_check",
        "name": "PSU Failure / Redundancy Lost",
        "severity": "Average",
        "description": "é›»æºãƒ¦ãƒ‹ãƒƒãƒˆã®éšœå®³ã¾ãŸã¯å†—é•·æ€§ãŒå¤±ã‚ã‚Œã¦ã„ã¾ã™",
        "condition_type": "field_gt",
        "field": "hw.psu_count",
        "value": 1,
        "threshold_macro": "{$PSU.STATUS.CRIT}",
        "default_value": "1",
        "unit": "status",
        "interval_macro": "{$PSU_CHECK_INTERVAL}",
        "default_interval": "3600"
    },
    {
        "id": "lag_check",
        "name": "LAG Interface Degraded",
        "severity": "Average",
        "description": "LAGãƒ¡ãƒ³ãƒãƒ¼ã®ä¸€éƒ¨ãŒãƒ€ã‚¦ãƒ³ã—ã¦ã„ã¾ã™",
        "condition_type": "tag_exists",
        "tag": "Configuration",
        "value": "LAG",
        "threshold_macro": None,
        "default_value": None,
        "unit": "",
        "interval_macro": "{$LAG_CHECK_INTERVAL}",
        "default_interval": "60"
    }
]

DEFAULT_TEMPLATE_MAPPING = {
    "mappings": [],
    "defaults": {
        "SWITCH": "Template Module Generic Switch SNMP",
        "ROUTER": "Template Module Generic Router SNMP",
        "FIREWALL": "Template Module Generic Firewall SNMP",
        "SERVER": "Template OS Linux by Zabbix agent",
        "default": "Template Module ICMP Ping"
    }
}

# ==================== ãƒ‡ãƒ¼ã‚¿I/Oé–¢æ•° ====================
def load_full_topology_data():
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’èª­ã¿è¾¼ã‚€"""
    path = os.path.join(DATA_DIR, "topology.json")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def load_json_config(filename, default_data):
    path = os.path.join(DATA_DIR, filename)
    if not os.path.exists(path):
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(default_data, f, indent=2, ensure_ascii=False)
        return default_data
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return default_data

def save_json_config(filename, data):
    path = os.path.join(DATA_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def save_trigger_rules(rules):
    save_json_config("trigger_rules.json", rules)

# ==================== AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ====================
class TemplateRecommenderAI:
    def __init__(self):
        self.api_key = st.secrets.get("GOOGLE_API_KEY") or os.getenv("GOOGLE_API_KEY")

    def sanitize_device_data(self, devices: List[Dict]) -> List[Dict]:
        sanitized_list = []
        for d in devices:
            clean_data = {
                "vendor": d.get("vendor", "Unknown"),
                "type": d.get("type", "Unknown"),
                "model": d.get("model", "")
            }
            if not clean_data["model"]:
                clean_data["model"] = "Unknown"
            sanitized_list.append(clean_data)
        return sanitized_list

    def recommend(self, raw_devices_summary: List[Dict]) -> List[Dict]:
        sanitized_devices = self.sanitize_device_data(raw_devices_summary)
        
        # å‡¦ç†çŠ¶æ³ã®è¡¨ç¤ºï¼ˆã‚¦ã‚§ã‚¤ãƒˆãªã—ï¼‰
        st.write(f"ğŸ” åˆ†æå¯¾è±¡: {len(sanitized_devices)} ãƒ‡ãƒã‚¤ã‚¹")
        
        # Google Gemini API
        if self.api_key and HAS_GEMINI:
            try:
                st.write("ğŸ¤– AI (Gemma 3) ã«å•ã„åˆã‚ã›ä¸­...")
                genai.configure(api_key=self.api_key)
                model = genai.GenerativeModel('gemma-3-12b-it')
                
                prompt = f"""
                You are a Zabbix configuration expert.
                Analyze the following list of network devices (JSON format) and identify the most appropriate standard SNMP template included in Zabbix 6.0/7.0 for each device.

                # Constraints
                - Output MUST be a valid JSON array only. Do not include markdown formatting.
                - Format each element as: {{"vendor": "...", "type": "...", "template": "..."}}
                - If no specific template is found, use "Template Module ICMP Ping".

                # Device List
                {json.dumps(sanitized_devices, ensure_ascii=False)}
                """
                
                response = model.generate_content(prompt)
                content = response.text
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0]
                elif "```" in content:
                    content = content.split("```")[0]
                
                return json.loads(content.strip())

            except Exception as e:
                st.error(f"AI API Error: {e}")
                st.warning("AIé€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        
        # Mock Logic (Waitç„¡ã—)
        st.write("ğŸ§  çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆä¸­ (Mock)...")
        recommendations = []
        for dev in sanitized_devices:
            vendor = dev['vendor'].lower()
            dtype = dev['type'].upper()
            template = "Template Module ICMP Ping"
            if "cisco" in vendor and dtype == "SWITCH": template = "Template Net Cisco IOS SNMP"
            recommendations.append({"vendor": dev['vendor'], "type": dev['type'], "template": template})
        
        return recommendations

# ==================== Zabbix API Client ====================
class ZabbixAPI:
    def __init__(self, url: str, token: str):
        self.url = url.rstrip('/') + '/api_jsonrpc.php'
        self.headers = {'Content-Type': 'application/json'}
        self.auth = token
        self.id_counter = 1

    def call(self, method: str, params: Any = None):
        payload = {"jsonrpc": "2.0", "method": method, "params": params or {}, "auth": self.auth, "id": self.id_counter}
        self.id_counter += 1
        try:
            response = requests.post(self.url, headers=self.headers, json=payload, timeout=10)
            response.raise_for_status()
            result = response.json()
            if 'error' in result: raise Exception(f"Zabbix API Error: {result['error']['data']}")
            return result.get('result')
        except Exception as e: raise Exception(f"Connection Failed: {str(e)}")

    def check_connection(self): return self.call("apiinfo.version")

class MockZabbixAPI:
    def __init__(self):
        self.url = "http://mock-zabbix/api"
        self.id_counter = 1
    def call(self, method: str, params: Any = None):
        if method == "apiinfo.version": return "6.4.0 (Mock)"
        elif method == "hostgroup.get": return []
        elif method == "hostgroup.create": return {"groupids": ["100"]}
        elif method == "template.get": return [{"templateid": "10001"}]
        elif method == "host.get": return []
        elif method == "host.create": return {"hostids": ["500"]}
        elif method == "host.update": return {"hostids": ["500"]}
        elif method == "action.create": return {"actionids": ["1"]}
        return {}
    def check_connection(self): return self.call("apiinfo.version")

# ==================== è¨­å®šç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ ====================
def determine_template(vendor, device_type, mapping_data):
    for rule in mapping_data.get("mappings", []):
        if rule.get("vendor") == vendor and rule.get("type") == device_type:
            return rule["template"]
    defaults = mapping_data.get("defaults", {})
    return defaults.get(device_type, defaults.get("default", "Template Module ICMP Ping"))

def generate_zabbix_config(full_data: Dict, options: Dict, trigger_rules: List, template_mapping: Dict) -> Dict:
    site_name = full_data.get("site_name", "Unknown-Site")
    topology = full_data.get("topology", {})
    connections = full_data.get("connections", [])
    module_master = st.session_state.get("module_master_list", ["LineCard", "Supervisor", "SFP+"])

    config = {
        "host_groups": [], "hosts": [], "actions": [], "dependencies": [], "summary": {}
    }
    
    if not topology: return config

    # 1. Host Groups
    groups = set()
    groups.add(site_name)
    for d in topology.values():
        dev_type = d.get("type", "Other")
        groups.add(f"{site_name}/{dev_type}")
    config["host_groups"] = [{"name": g} for g in sorted(groups)]

    # 2. Hosts
    for dev_id, dev_data in topology.items():
        meta = dev_data.get("metadata", {})
        hw = meta.get("hw_inventory", {})
        vendor = meta.get("vendor", "default")
        dev_type = dev_data.get("type", "Other")
        rack_info = meta.get("rack_info") or meta.get("location") or "Unspecified"
        
        host_groups = [{"name": site_name}, {"name": f"{site_name}/{dev_type}"}]
        template_name = determine_template(vendor, dev_type, template_mapping)
        
        interfaces = [{
            "type": 2, "main": 1, "useip": 1, "ip": "192.168.1.1", "dns": "", "port": "161",
            "details": {"version": 2, "community": "public"}
        }]

        macros = []
        if hw.get("psu_count"): macros.append({"macro": "{$EXPECTED_PSU_COUNT}", "value": str(hw["psu_count"])})
        if hw.get("fan_count"): macros.append({"macro": "{$EXPECTED_FAN_COUNT}", "value": str(hw["fan_count"])})
        for mod_name in module_master:
            count = hw.get("custom_modules", {}).get(mod_name, 0)
            safe_name = mod_name.upper().replace("-", "_").replace(" ", "_").replace("+", "PLUS")
            macros.append({"macro": f"{{$EXPECTED_{safe_name}_COUNT}}", "value": str(count)})

        for rule in trigger_rules:
            if rule.get("threshold_macro") and rule.get("default_value") is not None:
                macros.append({"macro": rule["threshold_macro"], "value": str(rule["default_value"])})
            if rule.get("interval_macro") and rule.get("default_interval") is not None:
                macros.append({"macro": rule["interval_macro"], "value": f"{rule['default_interval']}s"})

        tags = [
            {"tag": "Layer", "value": str(dev_data.get("layer", 0))},
            {"tag": "Vendor", "value": vendor},
            {"tag": "Model", "value": meta.get("model", "Unknown")},
            {"tag": "Location", "value": rack_info}
        ]
        
        has_lag = False
        vlan_ids = set()
        for c in connections:
            if c["from"] == dev_id or c["to"] == dev_id:
                c_meta = c.get("metadata", {})
                if c_meta.get("lag_enabled"): has_lag = True
                if c_meta.get("vlans"):
                    for v in c_meta["vlans"].replace(" ", "").split(","):
                        if v: vlan_ids.add(v)
        if has_lag: tags.append({"tag": "Configuration", "value": "LAG"})
        if vlan_ids: tags.append({"tag": "VLANs", "value": ",".join(sorted(vlan_ids))})

        host_obj = {
            "host": dev_id, "name": dev_id, "groups": host_groups,
            "interfaces": interfaces, "templates": [{"name": template_name}],
            "macros": macros, "tags": tags, "inventory_mode": 1,
            "description": f"Generated by RCA Tool.\nSite: {site_name}\nRack: {rack_info}\nVendor: {vendor}"
        }
        config["hosts"].append(host_obj)

    # 3. Dependencies
    for c in connections:
        if c["type"] == "uplink":
            child = c["from"]
            parent = c["to"]
            config["dependencies"].append({
                "host": child, "depends_on_host": parent,
                "description": f"Uplink: {child} -> {parent}"
            })

    # 4. Actions
    if options["create_action"]:
        config["actions"].append({
            "name": "Report problems to Admin",
            "eventsource": 0, "status": 0, "esc_period": "10m",
            "operations": [{"operationtype": 0, "opmessage_grp": [{"usrgrpid": "7"}], "opmessage": {"default_msg": 1, "mediatypeid": "1"}}]
        })

    config["summary"] = {
        "hosts": len(config["hosts"]),
        "groups": len(config["host_groups"]),
        "dependencies": len(config["dependencies"]),
        "actions": len(config["actions"])
    }
    return config

# ==================== APIæŠ•å…¥ãƒ­ã‚¸ãƒƒã‚¯ ====================
def push_config_to_zabbix(api: Any, config: Dict):
    logs = []
    st.write("ğŸ“‚ ãƒ›ã‚¹ãƒˆã‚°ãƒ«ãƒ¼ãƒ—ã‚’ç¢ºèªä¸­...")
    existing_groups = {g['name']: g['groupid'] for g in api.call("hostgroup.get", {"output": ["groupid", "name"]})}
    for group in config["host_groups"]:
        g_name = group["name"]
        if g_name not in existing_groups:
            res = api.call("hostgroup.create", {"name": g_name})
            existing_groups[g_name] = res['groupids'][0]
            logs.append(f"âœ… ã‚°ãƒ«ãƒ¼ãƒ—ä½œæˆ: {g_name}")
    
    st.write("ğŸ“„ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæƒ…å ±ã‚’å–å¾—ä¸­...")
    template_cache = {}
    def get_template_id(name):
        if name in template_cache: return template_cache[name]
        res = api.call("template.get", {"filter": {"host": name}, "output": ["templateid"]})
        if res:
            tid = res[0]['templateid']
            template_cache[name] = tid
            return tid
        return None

    st.write("ğŸ–¥ï¸ ãƒ›ã‚¹ãƒˆè¨­å®šã‚’åæ˜ ä¸­...")
    for host_conf in config["hosts"]:
        hostname = host_conf["host"]
        group_ids = [{"groupid": existing_groups[g["name"]]} for g in host_conf["groups"] if g["name"] in existing_groups]
        template_ids = []
        for t in host_conf["templates"]:
            tid = get_template_id(t["name"])
            if tid: template_ids.append({"templateid": tid})
            else: logs.append(f"âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæœªå®šç¾©: {t['name']} (ã‚¹ã‚­ãƒƒãƒ—)")

        host_payload = {
            "host": hostname, "name": host_conf["name"], "groups": group_ids,
            "interfaces": host_conf["interfaces"], "templates": template_ids,
            "macros": host_conf["macros"], "tags": host_conf["tags"], "inventory_mode": 1
        }

        existing = api.call("host.get", {"filter": {"host": hostname}, "output": ["hostid"]})
        if existing:
            host_payload["hostid"] = existing[0]['hostid']
            del host_payload["interfaces"] 
            api.call("host.update", host_payload)
            logs.append(f"ğŸ”„ ãƒ›ã‚¹ãƒˆæ›´æ–°: {hostname}")
        else:
            api.call("host.create", host_payload)
            logs.append(f"âœ¨ ãƒ›ã‚¹ãƒˆä½œæˆ: {hostname}")

    if config.get("actions"):
        st.write("ğŸ”” é€šçŸ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨­å®šä¸­...")
        for action in config["actions"]:
            exists = api.call("action.get", {"filter": {"name": action["name"]}})
            if not exists:
                api.call("action.create", action)
                logs.append(f"âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ: {action['name']}")

    st.write("ğŸ”— ä¾å­˜é–¢ä¿‚ã‚’è¨­å®šä¸­...")
    if config["dependencies"]:
        logs.append(f"â„¹ï¸ ä¾å­˜é–¢ä¿‚è¨­å®š: {len(config['dependencies'])} ä»¶")

    return logs

# ==================== UIãƒ¡ã‚¤ãƒ³å‡¦ç† ====================
def main():
    with st.sidebar:
        st.header("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
        uploaded_file = st.file_uploader("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (JSON)", type=["json"])
        
        st.divider()
        st.header("ğŸ”— Zabbixæ¥ç¶š")
        use_mock = st.checkbox("ğŸ§ª ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰", value=False)
        
        if "zabbix_connected" not in st.session_state:
            st.session_state.zabbix_connected = False
            st.session_state.is_mock = False

        zabbix_url = st.text_input("URL", "[http://192.168.1.100/zabbix](http://192.168.1.100/zabbix)", disabled=use_mock)
        zabbix_token = st.text_input("Token", type="password", disabled=use_mock)
        
        if st.button("æ¥ç¶šãƒ†ã‚¹ãƒˆ", use_container_width=True):
            try:
                if use_mock:
                    api = MockZabbixAPI()
                    st.session_state.is_mock = True
                else:
                    if not zabbix_url: raise Exception("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    api = ZabbixAPI(zabbix_url, zabbix_token)
                    st.session_state.is_mock = False
                
                ver = api.check_connection()
                st.session_state.zabbix_connected = True
                st.success(f"æ¥ç¶šOK: {ver}")
            except Exception as e:
                st.session_state.zabbix_connected = False
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("âš™ï¸ ç›£è¦–è¨­å®šç”Ÿæˆ (AI Assisted)")
    with col2:
        if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ", use_container_width=True):
            st.switch_page("Home.py")
    
    st.divider()

    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    full_data = None
    if uploaded_file:
        full_data = json.load(uploaded_file)
        st.info(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {uploaded_file.name}")
    else:
        full_data = load_full_topology_data()
        if full_data and full_data.get("topology"):
            st.info("ğŸ“‚ ã‚µãƒ¼ãƒãƒ¼ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
    
    # ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not full_data or not full_data.get("topology"):
        st.warning("âš ï¸ ãƒˆãƒãƒ­ã‚¸ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ãƒ‡ãƒã‚¤ã‚¹ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒˆãƒãƒ­ã‚¸ãƒ¼ãƒ“ãƒ«ãƒ€ãƒ¼ã§ãƒ‡ãƒã‚¤ã‚¹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return

    trigger_rules = load_json_config("trigger_rules.json", DEFAULT_TRIGGER_RULES)
    template_mapping = load_json_config("template_mapping.json", DEFAULT_TEMPLATE_MAPPING)

    # --- 1. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰²ã‚Šå½“ã¦ãƒ«ãƒ¼ãƒ« (AI) ---
    with st.expander("1. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‰²ã‚Šå½“ã¦ãƒ«ãƒ¼ãƒ« (Vendor/Typeå®šç¾©)", expanded=True):
        st.write("ãƒˆãƒãƒ­ã‚¸ãƒ¼å†…ã®ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ï¼ˆãƒ™ãƒ³ãƒ€ãƒ¼ã€ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’åˆ†æã—ã€æœ€é©ãªZabbixãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è‡ªå‹•å‰²ã‚Šå½“ã¦ã—ã¾ã™ã€‚")
        
        if st.button("âœ¨ AIã§æ¨å¥¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆãƒ»é©ç”¨", type="primary"):
            devices_summary = []
            seen = set()
            for d in full_data.get("topology", {}).values():
                meta = d.get("metadata", {})
                key = (meta.get("vendor"), d.get("type"), meta.get("model"))
                if key not in seen and key[0]:
                    seen.add(key)
                    devices_summary.append({"vendor": key[0], "type": key[1], "model": key[2]})
            
            if not devices_summary:
                st.warning("æœ‰åŠ¹ãªãƒ™ãƒ³ãƒ€ãƒ¼æƒ…å ±ã‚’æŒã¤ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                with st.status("ğŸ¤– AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆ†æä¸­...", expanded=True) as status:
                    ai = TemplateRecommenderAI()
                    recommendations = ai.recommend(devices_summary)
                    
                    st.write("ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã‚’æ›´æ–°ä¸­...")
                    current_mappings = template_mapping.get("mappings", [])
                    added_count = 0
                    for rec in recommendations:
                        exists = any(
                            m["vendor"] == rec["vendor"] and m["type"] == rec["type"] 
                            for m in current_mappings
                        )
                        if not exists:
                            current_mappings.append(rec)
                            added_count += 1
                    
                    template_mapping["mappings"] = current_mappings
                    save_json_config("template_mapping.json", template_mapping)
                    status.update(label="âœ… å®Œäº†", state="complete", expanded=False)
                
                st.success(f"âœ… {added_count} ä»¶ã®æ–°ã—ã„ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                st.rerun()

        if template_mapping.get("mappings"):
            st.caption("ç¾åœ¨ã®é©ç”¨ãƒ«ãƒ¼ãƒ«:")
            st.dataframe(pd.DataFrame(template_mapping["mappings"]), use_container_width=True)

    # --- 2. å…±é€šç›£è¦–ãƒãƒªã‚·ãƒ¼ (é–¾å€¤ãƒ»é–“éš”è¨­å®š) ---
    st.subheader("2. å…±é€šç›£è¦–ãƒãƒªã‚·ãƒ¼ (é–¾å€¤ãƒ»é–“éš”è¨­å®š)")
    
    with st.container(border=True):
        create_action = st.toggle("æ¨™æº–é€šçŸ¥è¨­å®šã‚’ä½œæˆ", value=True)
        st.divider()
        st.markdown("##### âš¡ ãƒˆãƒªã‚¬ãƒ¼è¨­å®š (é–¾å€¤ / ç›£è¦–é–“éš”)")
        st.caption("å„ç›£è¦–é …ç›®ã®é–¾å€¤ãŠã‚ˆã³ç›£è¦–é–“éš”ã‚’ç·¨é›†ã§ãã¾ã™ã€‚è¨­å®šå†…å®¹ã¯ã€Œä¿å­˜ã€å¾Œã«ã€ŒZabbixè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã€ã«åæ˜ ã•ã‚Œã¾ã™ã€‚")

        rows = []
        for r in trigger_rules:
            if r.get("threshold_macro") or r.get("interval_macro"):
                rows.append({
                    "Trigger Name": r["name"],
                    "Macro (Threshold)": r.get("threshold_macro", "-"),
                    "Threshold Value": r.get("default_value", "-"),
                    "Unit": r.get("unit", ""),
                    "Macro (Interval)": r.get("interval_macro", "-"),
                    "Interval (sec)": r.get("default_interval", "-"),
                    "_id": r["id"]
                })
        
        df_triggers = pd.DataFrame(rows)

        if not df_triggers.empty:
            edited_df = st.data_editor(
                df_triggers,
                column_config={
                    "Trigger Name": st.column_config.TextColumn("ç›£è¦–é …ç›®å", disabled=True, width="medium"),
                    "Macro (Threshold)": st.column_config.TextColumn("é–¾å€¤ãƒã‚¯ãƒ­", disabled=True, width="small"),
                    "Threshold Value": st.column_config.TextColumn("é–¾å€¤", required=True),
                    "Unit": st.column_config.TextColumn("å˜ä½", disabled=True, width="small"),
                    "Macro (Interval)": st.column_config.TextColumn("é–“éš”ãƒã‚¯ãƒ­", disabled=True, width="small"),
                    "Interval (sec)": st.column_config.TextColumn("ç›£è¦–é–“éš”(ç§’)", required=True),
                    "_id": None 
                },
                hide_index=True,
                use_container_width=True,
                num_rows="fixed"
            )

            if st.button("ğŸ’¾ è¨­å®šã‚’ä¿å­˜ã—ã¦åæ˜ ", type="primary"):
                is_changed = False
                for index, row in edited_df.iterrows():
                    rule_id = row["_id"]
                    new_thresh = row["Threshold Value"]
                    new_int = row["Interval (sec)"]
                    
                    for rule in trigger_rules:
                        if rule["id"] == rule_id:
                            if rule.get("default_value") != new_thresh:
                                rule["default_value"] = new_thresh
                                is_changed = True
                            if rule.get("default_interval") != new_int:
                                rule["default_interval"] = new_int
                                is_changed = True
                
                if is_changed:
                    save_trigger_rules(trigger_rules)
                    st.success("è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.info("å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.info("è¨­å®šå¯èƒ½ãªãƒ«ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # è¨­å®šç”Ÿæˆ
    options = {"create_action": create_action, "interval": 60}
    config = generate_zabbix_config(full_data, options, trigger_rules, template_mapping)
    
    st.subheader("1. è¨­å®šå†…å®¹ã®ç¢ºèª")
    
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ãƒ›ã‚¹ãƒˆæ•°", len(config["hosts"]))
    k2.metric("ã‚°ãƒ«ãƒ¼ãƒ—æ•°", len(config["host_groups"]))
    k3.metric("ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", len(config["actions"]))
    k4.metric("ä¾å­˜é–¢ä¿‚", len(config["dependencies"]))

    tab_host, tab_group, tab_dep, tab_json = st.tabs([
        "ğŸ–¥ï¸ ãƒ›ã‚¹ãƒˆè©³ç´°", "ğŸ“‚ ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆ", "ğŸ”— ä¾å­˜é–¢ä¿‚", "ğŸ” JSON"
    ])

    with tab_host:
        df_hosts = []
        for h in config["hosts"]:
            macros_display = []
            for m in h["macros"]:
                val = m['value']
                macros_display.append(f"{m['macro']}={val}")
            
            df_hosts.append({
                "ãƒ›ã‚¹ãƒˆå": h["host"],
                "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ": h["templates"][0]["name"],
                "ã‚°ãƒ«ãƒ¼ãƒ—": ", ".join([g["name"] for g in h["groups"]]),
                "é©ç”¨ãƒã‚¯ãƒ­": ", ".join(macros_display)
            })
        st.dataframe(pd.DataFrame(df_hosts), use_container_width=True)

    with tab_group:
        st.caption(f"â€» æ‹ ç‚¹å({full_data.get('site_name','Unknown')})/æ©Ÿå™¨ã‚¿ã‚¤ãƒ— ã®éšå±¤æ§‹é€ ")
        st.dataframe(pd.DataFrame(config["host_groups"]), use_container_width=True)

    with tab_dep:
        st.dataframe(pd.DataFrame(config["dependencies"]), use_container_width=True)

    with tab_json:
        st.json(config)

    st.divider()
    
    st.subheader("2. å®Ÿè¡Œ")
    c_dl, c_push = st.columns(2)
    
    with c_dl:
        st.download_button(
            "ğŸ“¥ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜",
            data=json.dumps(config, indent=2, ensure_ascii=False),
            file_name="zabbix_config.json",
            mime="application/json",
            use_container_width=True
        )
        
    with c_push:
        if not st.session_state.zabbix_connected:
            st.button("Zabbixã¸æŠ•å…¥ (æœªæ¥ç¶š)", disabled=True, use_container_width=True)
        elif len(config["hosts"]) == 0:
            st.button("ãƒ‡ãƒ¼ã‚¿ãªã—", disabled=True, use_container_width=True)
        else:
            if st.button("ğŸš€ Zabbixã¸æŠ•å…¥é–‹å§‹", type="primary", use_container_width=True):
                
                if st.session_state.is_mock:
                    api = MockZabbixAPI()
                else:
                    api = ZabbixAPI(zabbix_url, zabbix_token)
                
                with st.status("å‡¦ç†ã‚’å®Ÿè¡Œä¸­...", expanded=True) as status:
                    try:
                        logs = push_config_to_zabbix(api, config)
                        status.update(label="å®Œäº†ã—ã¾ã—ãŸ", state="complete", expanded=False)
                        st.success(f"æˆåŠŸ: {len(config['hosts'])} å°ã®å‡¦ç†ãŒå®Œäº†")
                        with st.expander("è©³ç´°ãƒ­ã‚°"):
                            for l in logs: st.write(l)
                    except Exception as e:
                        status.update(label="ã‚¨ãƒ©ãƒ¼", state="error")
                        st.error(f"è©³ç´°: {e}")

if __name__ == "__main__":
    main()
